---
layout: post
title: 无监督学习与进化适应性
comments: true
tags: [note,machine-learning]
slug: note
category: ml,"machine learning"
---

最近看进化心理学，有一个特性比较有意思，即进化形成的心理机制，被设计成只接收一小部分特定的信息 [^1] 。
人类没有把所有的技能都写在基因里面，而是写入了把可以习得技能的prior。 这种设计比较巧妙，有点授人以渔的意味在里面。人类的幼崽暴露在信息的海洋中，却能快速的形成人类生存所需要的各种技能。
这种自我学习与迭代的能力，少不了对于信息的筛选。

在这种prior的设计下，信息被有选择的接收，而这些有选择的数据筛选再加上一个高效（从信息压缩的角度）信息存储机制，就可以形成对于数据分布的建模。
这里值得探究的有两个方面，
+ 这种prior的设计机制如何
+ 在这个prior下，技能是如何学习的。


对于prior的设计机制，一种可能性是记录信息的共性，通过共性来判断，信息是否符合这种共性。无监督学习，其实也是大量使用了不变性，从而训练模型来得到一种信息提取的不变性---从信息中筛选出那些不变的特征。
比如，constrast learning, 主要是通过各种对于图像的变换，希望网络提取出来的信息不受变换的影响。

而这种不变性的信息提取，其实就是一种对于信息的抽象。这也让学习变得更加的容易。当我们学习一项技能的时候，我们不需要对于每一个特例都去学习对应的技巧，而是只需要学习上层如何进行规划这些不变性的high level task，一旦对于一个实例学习成功，就可以很轻松的迁移到其它的实例上。

最近在语言学上，Bert、GPT等的成功，或可看成大量的无监督训练，建立了语言的共性表达。通过简单的预测下一个词，从而可以学习到词与词之间的相似性。CLIP、codex的出现，开始建立起语言与文字之间的连接。
训练方法需要文本与图像、代码之间建立连接。
code本身其实也是一种语言，因此，人类语言到code生成，可以看成一种翻译任务，然而不同的地方在于，翻译允许一些小的纰漏而不影响整体的理解，然而代码是需要严格正确执行的。
一种好的方法或许是建立一些code block(或者我们可以称之为template)的东西，nlp2template, template2code. 当然，如果我们有足够的数据，我们或许可以绕过template这一个环节。
或者我们在生成的时候，能够有一些check 机制，保证代码的正确性 （say, 设计一个code review的模块)。
文本与图像的连接目前还少了一些味道。因为，文本之间的共性已经通过大量的无监督训练建立起来，但视觉图像这一块，还没有，目前的共性是靠文本桥接起来的。
无可厚非，这是一种方法，但仍然还少了一层“抽象”，即图像自身的大量的跟颜色、几何、空间相关的不变性，没有提前抽象出来。

因此，下一阶段的研究，或许可以放在图像的抽象上面。在两个抽象之间再建立连接，或许会更加的容易一些。所幸，transformer的引入以及一些图像的无监督算法的提出 (e.g., mask autoencoder)，逐渐让图像抽象开始有了更多有趣的进展。


[^1]: 马丁赛利格曼提出了一个命题，有机体通过进化。而先天的预备了学习某些事情，而非另一些事情的可能性。塞利格曼和同事发现，人们非常容易对某些对象，比如蛇建立起恐惧的条件反射，但是对另一些对象，比如电源插座，汽车却很难建立起恐惧的条件反射。
